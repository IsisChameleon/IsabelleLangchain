{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY \")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "GOOGLE_CSE_ID = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting link about poetry:  \n",
    "https://www.yippeecode.com/topics/update-packages-in-python-poetry/  \n",
    "   \n",
    "Summary of commands discussed.  \n",
    "  \n",
    "poetry show -l  \n",
    "poetry show -t  \n",
    "poetry add \"package==version\"    \n",
    "poetry add \"package[extra]==version\"  \n",
    "poetry add \"package==version\" --dev  \n",
    "poetry update  \n",
    "poetry env list --full-path  \n",
    "poetry env remove name-of-env  \n",
    "poetry env use $(which python3)  \n",
    "source $(dirname $(poetry run which python3))/activate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.7, 'max_tokens': 512, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=512)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Quantum mechanics is a physical theory that describes the behavior of matter and energy at the atomic and subatomic level.\n"
     ]
    }
   ],
   "source": [
    "output = llm('explain quantum mechanic in one sentence')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(llm.get_num_tokens('explain quantum mechanic in one sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Generation(text='\\n\\nParis.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThe formula for the area of a circle is A = πr², where r is the radius of the circle.', generation_info={'finish_reason': 'stop', 'logprobs': None})]]\n"
     ]
    }
   ],
   "source": [
    "output=llm.generate(['... is the capital of France', 'What is the formula for the area of a circle'])\n",
    "print(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Paris.\n"
     ]
    }
   ],
   "source": [
    "print(output.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate(['write an original tagline for a burger restaurant'] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"A Burger Above the Rest - At Our Place!\"\n",
      "\n",
      "\"Burgers That Will Leave You Wanting More!\"\n",
      "\n",
      "\"Take a Bite Into Our Juicy Burgers!\""
     ]
    }
   ],
   "source": [
    "for o in output.generations:\n",
    "    print(o[0].text, end='')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatModels: GPT-3.5-Turbo and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    AIMessage,  #assistant role\n",
    "    HumanMessage, #user role\n",
    "    SystemMessage  #system role\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat  = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5, max_tokens=1024)  #or gpt-3.5-turbo\n",
    "messages = [\n",
    "    SystemMessage(content='You are a physicist and respond only in french.'),\n",
    "    HumanMessage(content='Explain quantum mechanic in one sentence')\n",
    "]\n",
    "output = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mécanique quantique est la théorie physique qui décrit le comportement des particules subatomiques et leurs interactions, basée sur le principe de superposition et la dualité onde-particule.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['virus', 'language'] output_parser=None partial_variables={} template='YOu are an experienced virologist.\\nWrite a few sentences about the following {virus} in {language}' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "template = '''YOu are an experienced virologist.\n",
    "Write a few sentences about the following {virus} in {language}'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus', 'language'],\n",
    "    template=template\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "L’Ebola est une maladie virale grave qui se propage à travers les fluides corporels. Elle affecte principalement les humains et les primates, et peut entraîner des saignements internes et la mort. Les signes et symptômes comprennent la fièvre, la fatigue, la diarrhée et des maux de tête. La prévention et le traitement de l'Ebola reposent sur l'hygiène, la prise en charge médicale et l'isolement du patient.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7)\n",
    "output = llm(prompt.format(virus='ebola', language='french'))\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm=ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
    "\n",
    "template = '''YOu are an experienced virologist.\n",
    "Write a few sentences about the following {virus} in {language}'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus', 'language'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain=LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "output=chain.run({'virus':'MSV', 'language':'french'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le virus de la mosaïque du manioc (MSV) est un virus végétal qui affecte principalement les plantes de manioc. En tant que virologue expérimenté, j'ai étudié ce virus et ses effets sur les cultures agricoles. Le MSV provoque des symptômes de mosaïque sur les feuilles des plantes de manioc, ce qui réduit considérablement leur rendement et leur qualité. Des mesures de prévention et de contrôle sont nécessaires pour limiter la propagation de ce virus et protéger les cultures de manioc.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m.\n",
      "\n",
      "def linear_regression(x_values, y_values):\n",
      "    \"\"\"\n",
      "    Returns the coefficients of a linear regression line\n",
      "    given a list of x-values and y-values\n",
      "    \"\"\"\n",
      "    x_mean = sum(x_values) / len(x_values)\n",
      "    y_mean = sum(y_values) / len(y_values) \n",
      "    numerator = 0\n",
      "    denominator = 0\n",
      "    for i in range(len(x_values)):\n",
      "        numerator += (x_values[i] - x_mean) * (y_values[i] - y_mean)\n",
      "        denominator += (x_values[i] - x_mean) ** 2\n",
      "    m = numerator / denominator\n",
      "    b = y_mean - (m * x_mean)\n",
      "    return m, b\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe given python function `linear_regression` calculates the coefficients of a linear regression line based on a list of x-values and y-values.\n",
      "\n",
      "The function starts by calculating the mean (average) of the x-values and y-values using the formulas:\n",
      "- `x_mean = sum(x_values) / len(x_values)` to calculate the mean of x-values\n",
      "- `y_mean = sum(y_values) / len(y_values)` to calculate the mean of y-values\n",
      "\n",
      "Next, the function initializes two variables `numerator` and `denominator` as 0. These variables will be used in the following loop to calculate the coefficients of the linear regression line.\n",
      "\n",
      "The function then enters a loop that iterates through each index of the x_values (or y_values) list. In each iteration, the following calculations are performed:\n",
      "- `(x_values[i] - x_mean)` calculates the difference between the current x-value and the mean of x-values\n",
      "- `(y_values[i] - y_mean)` calculates the difference between the current y-value and the mean of y-values\n",
      "- `(x_values[i] - x_mean) * (y_values[i] - y_mean)` multiplies the differences calculated above to get the product\n",
      "\n",
      "In each iteration of the loop, the product obtained above is added to `numerator` and the second difference `(x_values[i] - x_mean) ** 2` is added to `denominator`.\n",
      "\n",
      "After the loop finishes, the function calculates the slope (m) of the linear regression line using the formula `m = numerator / denominator`.\n",
      "\n",
      "Lastly, the function calculates the y-intercept (b) of the linear regression line using the formula `b = y_mean - (m * x_mean)`.\n",
      "\n",
      "Finally, the function returns the slope (m) and y-intercept (b) of the linear regression line as a tuple. These coefficients represent the best fit line that minimizes the sum of squared distances between the observed data points and the line.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm1 =OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=1024)\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=['concept'],\n",
    "    template='''You are an experienced scientist and Python programmer.\n",
    "    Write a function that implements the concept of {concept}'''\n",
    ")\n",
    "chain1=LLMChain(llm=llm1, prompt=prompt1)\n",
    "\n",
    "llm2 =OpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['function'],\n",
    "    template='''Given the python function {function} describe it as detailed as possible.'''\n",
    ")\n",
    "chain2=LLMChain(llm=llm2, prompt=prompt2)\n",
    "\n",
    "overall_chain=SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "output = overall_chain.run('linear regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m to input scores.\n",
      "\n",
      "def softmax(x):\n",
      "    \"\"\"Compute softmax values for each sets of scores in x\"\"\"\n",
      "    return np.exp(x) / np.sum(np.exp(x), axis=0)\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe function \"softmax\" is implementing the softmax activation function in Python. This activation function is commonly used when dealing with multi-class classification problems. It takes a vector of scores as input and computes the softmax values for each set of scores.\n",
      "\n",
      "The function calculates the exponential of each element in the input vector x using np.exp(x). This is because softmax requires exponentiation to make the scores positive and meaningful for probabilities. \n",
      "\n",
      "Then, it computes the sum of the exponentiated scores along the specified axis (axis=0 in this case) using np.sum(). This sum is necessary to normalize the scores and ensure they add up to 1.\n",
      "\n",
      "Finally, it divides each exponentiated score by the sum computed earlier to obtain the softmax values for each score. This is done by dividing np.exp(x) by the result of np.sum(np.exp(x), axis=0).\n",
      "\n",
      "Overall, the function takes in a vector of scores and returns the softmax activation values for each score. The output will be a vector of probabilities that sum up to 1, representing the likelihood of the input belonging to each class or category.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = overall_chain.run('softmax')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
